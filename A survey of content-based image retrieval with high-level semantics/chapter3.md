## 3. Giảm khoảng cách ngữ nghĩa
Các kỹ thuật tiên tiến trong việc giảm khoảng cách ngữ nghĩa có thể được phân loại theo nhiều cách khác nhau từ các góc độ khác nhau. Ví dụ, bằng cách xem xét miền ứng dụng, chúng có thể được phân loại thành những kỹ thuật nhắm mục tiêu vào truy xuất tác phẩm nghệ thuật, truy xuất hình ảnh phong cảnh, truy xuất hình ảnh WWW, v.v.. Trong bài báo này, chúng tôi tập trung vào các kỹ thuật được sử dụng để suy ra ngữ nghĩa cấp cao và xác định năm loại như sau: 
1. Sử dụng ngữ hệ đối tượng (object ontology) để định nghĩa các khái niệm cấp cao . 
2. Sử dụng các phương pháp học có giám sát hoặc không giám sát để liên kết các đặc trưng cấp thấp với các khái niệm truy vấn.
3. Giới thiệu phản hồi liên quan (RF) vào vòng lặp truy xuất để liên tục học ý định của người dùng. 
4. Tạo mẫu ngữ nghĩa (ST) để hỗ trợ truy xuất ảnh cấp cao.
5. Sử dụng cả thông tin văn bản

<p align="center">
  <img src="/figures/fig4.png" alt=" Hình 4. Ngữ hệ đối tượng được sử dụng trong Tài liệu" width="500"/>
  <br>
  <em> Hình 4. Ngữ hệ đối tượng được sử dụng trong Tài liệu</em>
</p>
thông tin thu được từ Web và nội dung trực quan của hình ảnh để truy xuất hình ảnh Web. Nhiều hệ thống khai thác một hoặc nhiều kỹ thuật trên để triển khai truy xuất hình ảnh dựa trên ngữ nghĩa cấp cao. Ví dụ, (3) thường được kết hợp với (1), (2) hoặc (5), (5) thường được kết hợp với bốn kỹ thuật còn lại.

### 3.1. Ngữ hệ đối tượng
Trong một số trường hợp, ngữ nghĩa có thể dễ dàng được suy ra từ ngôn ngữ hàng ngày của chúng ta. Ví dụ, bầu trời có thể được mô tả là "vùng trên, đồng nhất và màu xanh". Trong các hệ thống sử dụng ngữ nghĩa đơn giản như vậy, đầu tiên, các khoảng khác nhau được định nghĩa cho các đặc trưng hình ảnh cấp thấp, với mỗi khoảng tương ứng với một mô tả hình ảnh cấp trung gian, ví dụ, "xanh nhạt, xanh vừa, xanh đậm". Các mô tả này tạo thành một từ vựng đơn giản, cái gọi là "ngữ hệ đối tượng" (object-ontology), cung cấp một định nghĩa định tính về các khái niệm truy vấn cấp cao. Các hình ảnh trong cơ sở dữ liệu có thể được phân loại vào các danh mục khác nhau bằng cách ánh xạ các mô tả như vậy đến ngữ nghĩa cấp cao (từ khóa) dựa trên kiến thức của chúng ta , ví dụ, "bầu trời" có thể được định nghĩa là vùng có "màu xanh nhạt" (màu sắc), "đồng nhất" (kết cấu) và "phía trên" (vị trí không gian).
Lượng tử hóa đặc trưng màu sắc và kết cấu là chìa khóa trong các hệ thống như vậy. Để hỗ trợ truy xuất ảnh dựa trên ngữ nghĩa, một cách hiệu quả và được sử dụng rộng rãi hơn để lượng tử hóa thông tin màu sắc là bằng cách đặt tên màu. Mặc dù hàng triệu màu có thể được định nghĩa trong hệ thống máy tính, nhưng số màu mà người dùng có thể đặt tên chỉ giới hạn khoảng 10-20. Các mô hình đặt tên màu nhằm mục đích liên hệ một không gian màu số với các tên màu ngữ nghĩa được sử dụng trong ngôn ngữ tự nhiên. Hệ thống đặt tên màu nổi tiếng là "CNS" (hệ thống đặt tên màu)
được đề xuất bởi Berk, Brownston và Kaufman. 'CNS' lượng tử hóa không gian HSL thành 627 màu riêng biệt. Ý tưởng cơ bản là lượng tử hóa giá trị màu sắc thành một tập hợp các màu cơ bản. Độ bão hòa và độ sáng được lượng tử hóa thành các bin khác nhau làm các tính từ biểu thị sự phong phú và độ sáng của màu sắc. Toàn bộ tập hợp các tên màu cơ bản trong CNS là đỏ, cam, nâu, vàng, xanh lá cây, xanh dương và tím, với sự bổ sung của các thuật ngữ không màu như đen, xám và trắng, tạo thành 10 màu cơ bản. Trong tài liệu, 12 sắc độ được định nghĩa là màu cơ bản, bao gồm vàng, đỏ, xanh lá cây, xanh dương, cam, tím, và sáu màu khác được tạo thành từ sự kết hợp tuyến tính của chúng. Sau đó, năm cấp độ độ sáng và ba cấp độ độ bão hòa được xác định. Điều này tạo ra 180 màu tham chiếu. Để liên hệ màu sắc với biểu cảm (cảm xúc) và ấn tượng (thị giác) cho việc truy xuất tranh vẽ, các loại tương phản khác nhau được định nghĩa, chẳng hạn như tương phản sáng-tối, tương phản nóng-lạnh, tương phản bổ sung, v.v.. Ví dụ, màu vàng và cam được gọi là màu nóng, xanh lá cây và xanh dương được gọi là màu lạnh. Ví dụ truy vấn là "tìm những bức tranh có các tương phản sau: sáng-tối, lạnh-nóng".
Trong tài liệu, màu chủ đạo của một vùng (trong không gian HSV) được chuyển đổi thành một tập hợp 35 tên màu ngữ nghĩa như: đỏ, cam, vàng, nâu, v.v.. Tên màu ngữ nghĩa liên quan đến các đối tượng trong hình ảnh cảnh tự nhiên như cỏ, bầu trời. Ví dụ truy vấn là "tìm hình ảnh có vùng màu xanh da trời". Trong tài liệu, dựa trên quan sát của tác giả rằng một số lượng nhỏ màu sắc thường đủ để đặc trưng thông tin màu sắc trong vùng hình ảnh, tám màu được định nghĩa dựa trên giá trị RGB của chúng: đỏ, xanh lá cây, xanh dương, vàng, magenta, cyan, đen và trắng. Các tên màu này liên quan đến các đối tượng trong cảnh tự nhiên, ví dụ, màu trắng liên quan đến tuyết, mây, v.v.. Bằng cách này, hệ thống giảm "khoảng cách ngữ nghĩa" và hỗ trợ truy vấn bằng từ khóa. Tương tự như CNS, cũng có nhu cầu song song về một hệ thống đặt tên kết cấu để chuẩn hóa mô tả và biểu diễn kết cấu. Tuy nhiên, việc đặt tên kết cấu được cho là khó khăn hơn và cho đến nay vẫn chưa có một hệ thống đặt tên kết cấu như vậy. Là bước đầu tiên để tạo ra một hệ thống đặt tên kết cấu, một số nhà nghiên cứu cố gắng xác định các đặc trưng quan trọng mà con người sử dụng trong nhận thức kết cấu. Dựa trên thử nghiệm chủ quan, Rao và Lohse đã chỉ ra rằng tính lặp lại, tính định hướng và độ phức tạp là ba thuộc tính quan trọng nhất đối với nhận thức kết cấu của con người. Tuy nhiên, làm thế nào để thu được các đặc trưng này, và làm thế nào để ánh xạ các đặc trưng kết cấu cấp thấp khác đến ba miền này vẫn cần được nghiên cứu thêm.
So với màu sắc, kết cấu chưa được mô hình hóa và hiểu rõ, vẫn còn nhiều nghiên cứu cần được thực hiện. Thay vì sử dụng tên kết cấu làm từ khóa truy vấn, điều mà cho đến nay vẫn chưa thể thực hiện được, một số nhà nghiên cứu lượng tử hóa các đặc trưng kết cấu cảm nhận thành các khoảng khác nhau và định nghĩa các mô tả kết cấu có ý nghĩa. Trong tài liệu, các đặc trưng Tamura được lượng tử hóa thành các cấp độ khác nhau như rất thô, thô vừa, mịn, rất mịn; độ tương phản thấp, độ tương phản cao, v.v.. Sự kết hợp của các đặc trưng đó trong các mối quan hệ logic với "và", "hoặc" tạo thành các truy vấn như "tìm các kết cấu rất mịn và độ tương phản thấp".
Đối với cơ sở dữ liệu chứa các hình ảnh được thu thập đặc biệt, ngữ nghĩa đơn giản như vậy được dẫn xuất dựa trên ngữ hệ đối tượng có thể hoạt động tốt. Tuy nhiên, với các bộ sưu tập hình ảnh lớn với nhiều nội dung khác nhau, cần có các công cụ mạnh mẽ hơn để học ngữ nghĩa. 

### 3.2. Học máy
Trong hầu hết các trường hợp, để suy ra các đặc trưng ngữ nghĩa cấp cao, cần sử dụng các công cụ chính thức như kỹ thuật học máy có giám sát hoặc không giám sát. Mục tiêu của học có giám sát là dự đoán giá trị của một phép đo kết quả (ví dụ: nhãn danh mục ngữ nghĩa) dựa trên một tập hợp các phép đo đầu vào. Trong học không giám sát, không có phép đo kết quả, và mục tiêu là mô tả cách dữ liệu đầu vào được tổ chức hoặc phân cụm.

#### 3.2.1. Học có giám sát
Học có giám sát như máy vector hỗ trợ (SVM), bộ phân loại Bayesian thường được sử dụng để học các khái niệm cấp cao từ các đặc trưng ảnh cấp thấp. Với nền tảng lý thuyết vững chắc, SVM đã được sử dụng để nhận dạng đối tượng, phân loại văn bản, v.v. và được coi là một ứng cử viên tốt cho việc học trong hệ thống truy xuất ảnh. SVM ban đầu được thiết kế để phân loại nhị phân. Giả sử chúng ta có một tập hợp dữ liệu huấn luyện {x1, x2, . . . , xn} dưới dạng các vector trong không gian X ⊆ Rd thuộc hai lớp riêng biệt với nhãn của chúng {y1, y2, . . . , yn} và yi ∈ {−1, 1}. Chúng ta muốn tìm một siêu phẳng để phân tách dữ liệu. Trong số nhiều siêu phẳng có thể có, siêu phẳng phân tách tối ưu (OSP) là siêu phẳng tối đa hóa biên (khoảng cách giữa siêu phẳng và điểm dữ liệu gần nhất của mỗi lớp). Như trong Hình 5, các vector nằm ở một phía được gán nhãn là −1, và các vector nằm ở phía còn lại được gán nhãn là +1. "Vector hỗ trợ" đề cập đến các mẫu huấn luyện nằm gần siêu phẳng nhất. Để học nhiều
biên độ w
<p align="center">
  <img src="/figures/fig5.png" alt="Hình 5. Một máy vector hỗ trợ tuyến tính đơn giản." width="500"/>
  <br>
  <em>Hình 5. Một máy vector hỗ trợ tuyến tính đơn giản.</em>
</p>
các khái niệm cho truy xuất hình ảnh, một SVM phải được huấn luyện cho từng khái niệm. Ví dụ, trong tài liệu, SVM được sử dụng để chú thích hình ảnh. Trong giai đoạn huấn luyện, một mô hình SVM nhị phân được huấn luyện cho mỗi trong số 23 khái niệm được chọn. Trong giai đoạn thử nghiệm, các vùng không có nhãn được đưa vào tất cả các mô hình, khái niệm từ mô hình cho kết quả dương cao nhất sẽ được liên kết với vùng đó. Một phương pháp học được sử dụng rộng rãi khác là phân loại Bayesian. Trong tài liệu, sử dụng bộ phân loại Bayesian nhị phân, các khái niệm cấp cao của cảnh tự nhiên được thu nhận từ các đặc trưng ảnh cấp thấp. Các ảnh cơ sở dữ liệu được tự động phân loại thành các loại chung như trong nhà/ngoài trời, và các ảnh ngoài trời được phân loại thêm thành thành phố/phong cảnh, v.v.. Trong tài liệu, mạng Bayesian được sử dụng để phân loại ảnh trong nhà/ngoài trời.
Các kỹ thuật học khác như mạng nơ-ron cũng được sử dụng để học khái niệm. Trong tài liệu, đầu tiên, tác giả chọn 11 danh mục (khái niệm): gạch, mây, lông, cỏ, băng, đường, đá, cát, da, cây và nước. Sau đó, một lượng lớn dữ liệu huấn luyện (các đặc trưng cấp thấp của các vùng được phân đoạn) được đưa vào các bộ phân loại mạng nơ-ron để thiết lập liên kết giữa các đặc trưng cấp thấp của một hình ảnh và ngữ nghĩa cấp cao của nó (nhãn danh mục). Một nhược điểm của thuật toán này là nó yêu cầu một lượng lớn dữ liệu huấn luyện và tốn nhiều tài nguyên tính toán.

Trong tài liệu, có nêu rằng các thuật toán học truyền thống gặp phải hai vấn đề: (1) cần một lượng lớn mẫu huấn luyện được dán nhãn, và việc cung cấp dữ liệu như vậy rất tẻ nhạt và dễ gây lỗi; (2) tập huấn luyện được cố định trong các giai đoạn học và ứng dụng. Do đó, nếu miền ứng dụng thay đổi, các mẫu được dán nhãn mới phải được cung cấp để đảm bảo hiệu quả của bộ phân loại. Một phương pháp khởi động (bootstrapping) được trình bày trong tài liệu để giải quyết các vấn đề này. Nó bắt đầu từ một tập hợp nhỏ các mẫu huấn luyện được dán nhãn. Bằng cách sử dụng phương pháp đồng huấn luyện (co-training), trong đó hai bộ phân loại độc lập về mặt thống kê được sử dụng để đồng huấn luyện và đồng chú thích các mẫu không được dán nhãn, thuật toán  chú thích liên tục một tập hợp lớn hơn các mẫu không được dán nhãn. Các thí nghiệm của họ cho thấy độ chính xác truy xuất được cải thiện 10% so với SVM (400 ảnh được dán nhãn để huấn luyện), với số lượng mẫu huấn luyện được dán nhãn ít hơn nhiều (chỉ 20 hạt giống được dán nhãn). Ngoài các thuật toán đã đề cập ở trên, các kỹ thuật cây quyết định (học có giám sát) cũng được sử dụng để suy ra các đặc trưng ngữ nghĩa. Các phương pháp tạo cây quyết định như ID3, C4.5 (phiên bản cải tiến của ID3) và CART xây dựng một cấu trúc cây bằng cách chia không gian thuộc tính đầu vào một cách đệ quy thành một tập hợp các không gian không chồng lấn. Một tập hợp các quy tắc quyết định có thể thu được bằng cách đi theo các đường từ gốc cây đến các lá. Trong tài liệu, phương pháp cây quyết định CART được sử dụng để suy ra các quy tắc quyết định ánh xạ phân bố màu toàn cục (biểu đồ màu không gian HSV) trong một hình ảnh đã cho đến mô tả văn bản (bốn từ khóa: Hoàng hôn, Biển, Ảnh khô hạn và Cảnh đêm). Trong tài liệu, một cây quyết định C4.5 được xây dựng dựa trên một tập hợp các hình ảnh liên quan đến truy vấn, và sau đó được sử dụng làm mô hình để phân loại các hình ảnh cơ sở dữ liệu thành hai lớp: liên quan và không liên quan. Thuật toán này được sử dụng trong vòng lặp RF (sẽ được thảo luận trong Phần 3.3) để cung cấp các hình ảnh liên quan cho người dùng dán nhãn ở lần lặp tiếp theo. Một phương pháp tương tự được sử dụng trong tài liệu. Để nâng cao hiệu suất của RF, hệ thống sử dụng cây quyết định ID3 để phân loại các hình ảnh là liên quan/không liên quan dựa trên các đặc trưng màu sắc của chúng, thay vì trực tiếp xếp hạng các hình ảnh bằng cách sử dụng truy vấn đã sửa đổi thu được trong lần lặp cuối.
So với các phương pháp học khác, học cây quyết định đơn giản về mặt khái niệm, mạnh mẽ đối với các đặc trưng đầu vào không đầy đủ và nhiễu. Ngoài ra, cây quyết định có thể dễ dàng được dịch thành một tập hợp các quy tắc có thể được tích hợp vào một hệ thống chuyên gia để ra quyết định tự động. Tuy nhiên, để được sử dụng trong việc học các khái niệm cấp cao cho truy xuất ảnh, vấn đề cơ bản là thiếu tính mô-đun. Ví dụ, các phương pháp đã đề cập ở trên sử dụng các thuộc tính đầu vào định danh, nhưng các đặc trưng ảnh cấp thấp thường có các giá trị liên tục. Mặc dù một số thuật toán đã được thiết kế để phân loại các thuộc tính liên tục, nhưng việc các thuật toán được thiết kế chung này có luôn cung cấp sự phân chia có ý nghĩa của không gian đặc trưng ảnh hay không là một câu hỏi.

#### 3.2.2. Học không giám sát
Không giống như học có giám sát, trong đó sự hiện diện của biến kết quả hướng dẫn quá trình học, học không giám sát không có phép đo kết quả, nhiệm vụ là tìm ra cách các đặc trưng đầu vào được tổ chức hoặc phân cụm. Phân cụm ảnh là kỹ thuật học không giám sát điển hình cho mục đích truy xuất. Nó nhằm mục đích nhóm một tập hợp dữ liệu ảnh theo cách tối đa hóa sự tương đồng trong các cụm và tối thiểu hóa sự tương đồng giữa các cụm khác nhau. Mỗi cụm kết quả được liên kết với một nhãn lớp và các ảnh trong cùng một cụm được cho là tương tự nhau.
Thuật toán phân cụm k-means truyền thống và các biến thể của nó thường được sử dụng để phân cụm hình ảnh. Trong tài liệu, phân cụm k-means được áp dụng cho các đặc trưng màu sắc cấp thấp của một tập hợp hình ảnh huấn luyện. Sau đó, các thống kê đo lường sự thay đổi trong mỗi cụm được sử dụng để suy ra một tập hợp các ánh xạ giữa các đặc trưng cấp thấp và đặc trưng văn bản tối ưu (từ khóa) của cụm tương ứng. Các quy tắc ánh xạ được suy ra có thể được sử dụng tiếp để lập chỉ mục các hình ảnh mới chưa được gắn thẻ vào cơ sở dữ liệu. Trong tài liệu, để tự động chú thích các hình ảnh cơ sở dữ liệu cho mục đích truy xuất, hệ thống đầu tiên phân cụm các vùng hình ảnh thành các cụm vùng sử dụng một biến thể của phân cụm k-means được gọi là k-means có ràng buộc cặp đôi (PCK-means). Số lượng cụm được đặt theo kinh nghiệm là 300. Sau đó, xác suất hậu nghiệm của mỗi khái niệm (59 khái niệm được định nghĩa cho cơ sở dữ liệu hình ảnh được sử dụng) cho một vùng được suy ra bằng phương pháp Bayesian bán-ngây thơ. Do đó, một hình ảnh mới có thể được chú thích bằng cách chọn các khái niệm có xác suất cao nhất.
Hình ảnh truy vấn Đặc trưng ảnh cơ sở dữ liệu được lưu trữ Đo lường độ tương đồng Kết quả xếp hạng Chọn ảnh lân cận Phân cụm ảnh Hiển thị và phản hồi CLUE 
<p align="center">
  <img src="/figures/fig6.png" alt="Hình 6. Truy xuất ảnh với CLUE." width="500"/>
  <br>
  <em>Hình 6. Truy xuất ảnh với CLUE.</em>
</p>
Hình 6. Truy xuất ảnh với CLUE
Do sự phân bố phức tạp của dữ liệu hình ảnh (các điểm dữ liệu được lấy mẫu từ manifold phi tuyến), các phương pháp truyền thống như phân cụm k-means thường không thể phân tách tốt các hình ảnh với các khái niệm khác nhau. Để xử lý vấn đề này, một phương pháp phân cụm phổ được đề xuất là Normalized cut (NCut) và đã được sử dụng thành công trong một số ứng dụng như phân đoạn hình ảnh, phân cụm hình ảnh. Một phiên bản mở rộng của NCut có thể được tìm thấy trong tài liệu. Trong tài liệu, một phương pháp tên là "CLUE" được trình bày để giảm "khoảng cách ngữ nghĩa" trong CBIR. Không giống như các hệ thống CBIR khác hiển thị các hình ảnh đích được khớp hàng đầu cho người dùng, hệ thống này cố gắng truy xuất các cụm hình ảnh có ngữ nghĩa nhất quán. Với một hình ảnh truy vấn, một tập hợp các hình ảnh đích tương tự với truy vấn được chọn làm lân cận của truy vấn. Dựa trên giả thuyết rằng các hình ảnh có cùng ngữ nghĩa có xu hướng được phân cụm, phân cụm NCut được sử dụng để phân cụm các hình ảnh đích này thành các lớp ngữ nghĩa khác nhau. Sau đó, hệ thống hiển thị các cụm hình ảnh và điều chỉnh mô hình đo lường độ tương đồng theo phản hồi của người dùng. Hình 6 là sơ đồ của hệ thống. Mặc dù thành công trong phân cụm dữ liệu manifold, NCut không thể tạo ra một hàm ánh xạ rõ ràng. Để xử lý các điểm dữ liệu mới, độ tương đồng giữa các điểm mới và tất cả dữ liệu huấn luyện phải được đo lường. Việc tính toán độ tương đồng có thể rất phức tạp do kích thước lớn của tập huấn luyện. Để giải quyết các vấn đề này, trong tài liệu, một phương pháp phân cụm bảo toàn cục bộ (LPC) được đề xuất cho phân cụm hình ảnh. LPC có thể cung cấp một hàm ánh xạ rõ ràng. Kết quả thực nghiệm cho thấy LPC cung cấp độ chính xác truy xuất tương đương với NCut, nhưng hiệu quả tính toán hơn. Ngoài ra, kết quả truy xuất của LPC được chứng minh là chính xác hơn so với phân cụm k-means. Phân loại xác suất dựa trên lý thuyết Bayes là một trong những công cụ phân cụm mạnh mẽ nhất. Bộ phân loại maximum-a-posteriori (MAP) và biến thể của nó là bộ phân loại maximum-likelihood (ML) đã cho thấy nhiều hứa hẹn cho vấn đề CBIR. Tuy nhiên, theo truyền thống, việc áp dụng các bộ phân loại này khó khăn do sự phức tạp của hàm tương đồng MAP. Trong tài liệu, Vasconelos đã chỉ ra rằng hàm tương đồng có thể được tính toán hiệu quả khi các lượng tử hóa vector và hỗn hợp Gauss được sử dụng làm mô hình cho các hàm mật độ xác suất của các đặc trưng ảnh.

#### 3.2.3. Các kỹ thuật nhận dạng đối tượng cho truy xuất hình ảnh
Nhận dạng đối tượng trong hình ảnh là một vấn đề quan trọng trong thị giác máy tính với các ứng dụng trong chú thích ảnh, giám sát và truy xuất ảnh. Các thuật toán nhận dạng đối tượng có giám sát hoặc không giám sát đã được phát triển gần đây có thể được sử dụng cho truy xuất ảnh dựa trên ngữ nghĩa. Ví dụ, trong tài liệu, một phương pháp học không giám sát bất biến tỷ lệ được trình bày để học và nhận dạng các mô hình lớp đối tượng từ các cảnh lộn xộn không được gán nhãn và không được phân đoạn. Trong phương pháp này, các đối tượng được mô hình hóa như các chòm sao linh hoạt của các bộ phận và một biểu diễn xác suất được sử dụng cho tất cả các khía cạnh của đối tượng: hình dạng, diện mạo, sự che khuất và tỷ lệ tương đối. Trong nhận dạng, mô hình này được sử dụng theo cách Bayesian để phân loại ảnh. Tính linh hoạt của mô hình được chứng minh bằng các kết quả xuất sắc trên một loạt các bộ dữ liệu bao gồm các lớp bị ràng buộc hình học (như khuôn mặt, ô tô) và các đối tượng linh hoạt (như động vật).
Người ta nhận thấy rằng hầu hết người dùng thích truy xuất hình ảnh dựa trên các đối tượng trong hình ảnh. Trong tài liệu, các tác giả đã phát triển một phiên bản bán giám sát mới của thuật toán EM để học phân bố của các lớp đối tượng. Hình ảnh được biểu diễn dưới dạng các tập hợp vector đặc trưng của nhiều loại vùng trừu tượng. Mỗi vùng trừu tượng được mô hình hóa như một hỗn hợp các phân bố Gauss trên không gian đặc trưng của nó. Vì các vùng được sử dụng trong nhận dạng có thể đến từ các quy trình phân đoạn khác nhau, các vùng được sử dụng được gọi là "vùng trừu tượng". Một phần quan trọng của cách tiếp cận này là nó không cần biết vị trí của các đối tượng trong mỗi hình ảnh. Các thử nghiệm trên một tập hợp 860 hình ảnh chứng minh hiệu quả của cách tiếp cận.
Trong tài liệu, một phương pháp học tạo sinh/phân biệt hai pha được đề xuất, có thể học cách nhận dạng đối tượng bằng cách sử dụng nhiều loại đặc trưng. Mục tiêu của công trình này là phát triển một phương pháp phân loại tự động cho hình ảnh cảnh ngoài trời. Pha tạo sinh chuẩn hóa độ dài mô tả của hình ảnh, có thể có số lượng đặc trưng được trích xuất tùy ý của mỗi loại. Trong pha phân biệt, một bộ phân loại học được những hình ảnh nào, được biểu diễn bằng mô tả có độ dài cố định này, chứa đối tượng mục tiêu. Kết quả thực nghiệm của họ, sử dụng các đặc trưng màu sắc, kết cấu và cấu trúc, cho thấy hiệu suất truy xuất đầy hứa hẹn trên 31 danh mục đối tượng cơ bản và 20 khái niệm cấp cao. Hầu hết các phương pháp hiện tại để học các danh mục đối tượng hình ảnh đều yêu cầu hàng nghìn hình ảnh huấn luyện. Ngoài ra, hầu hết các thuật toán được trình bày trong tài liệu chỉ được thử nghiệm trên khoảng 10–20 danh mục đối tượng. Trong tài liệu, một thuật toán Bayesian tăng dần đã được phát triển để học các mô hình tạo sinh của các danh mục đối tượng chỉ từ vài hình ảnh huấn luyện. Phương pháp này sử dụng thông tin tiên nghiệm, được thu thập từ các danh mục đối tượng đã được học trước đó. Một mô hình xác suất tạo sinh được sử dụng để biểu diễn hình dạng và diện mạo của một chòm sao các đặc trưng thuộc về đối tượng. Các tham số của mô hình được học một cách tăng dần theo kiểu Bayesian. Thuật toán được thử nghiệm trên hình ảnh của 101 danh mục đối tượng đa dạng bao gồm khuôn mặt, máy tính xách tay, dâu tây, ngựa vằn, cốc, ghế, v.v..

### 3.3. Phản hồi liên quan
So với các thuật toán xử lý ngoại tuyến đã thảo luận ở trên, RF là một quá trình xử lý trực tuyến cố gắng học ý định của người dùng ngay lập tức. 
RF là một công cụ mạnh mẽ theo truyền thống được sử dụng trong các hệ thống truy xuất thông tin dựa trên văn bản. Nó được giới thiệu vào CBIR vào giữa những năm 1990, với mục đích đưa người dùng vào vòng lặp truy xuất để giảm "khoảng cách ngữ nghĩa" giữa những gì truy vấn biểu thị (các đặc trưng cấp thấp) và việc chúng có liên quan (ví dụ tích cực)/không liên quan (ví dụ tiêu cực) đến truy vấn hay không và ở mức độ nào. (3) Thuật toán học máy được áp dụng để học phản hồi của người dùng. Sau đó quay lại bước (2). Các bước (2)-(3) được lặp lại cho đến khi người dùng hài lòng với kết quả. Hình 7 cho thấy một sơ đồ đơn giản của hệ thống CBIR với RF.
Một cách tiếp cận điển hình trong bước (3) là điều chỉnh trọng số của các đặc trưng cấp thấp để đáp ứng nhu cầu của người dùng (tái trọng số). Bằng cách này, gánh nặng chỉ định trọng số được loại bỏ khỏi người dùng. Ví dụ về các hệ thống như vậy có trong tài liệu. "Tái trọng số" cập nhật động các trọng số được nhúng trong truy vấn (không chỉ trọng số cho các loại đặc trưng khác nhau như màu sắc, kết cấu, hình dạng, mà còn cả trọng số cho các thành phần khác nhau trong cùng một vector đặc trưng) để mô hình hóa các khái niệm cấp cao và tính chủ quan của nhận thức.

<p align="center">
  <img src="/figures/fig6.png" alt=" Hình 7. CBIR với RF." width="500"/>
  <br>
  <em> Hình 7. CBIR với RF.</em>
</p>


Một phương pháp khác được gọi là di chuyển điểm truy vấn (QPM). QPM cải thiện ước tính điểm truy vấn điểm bằng cách di chuyển nó về phía các ví dụ tích cực và ra xa khỏi các ví dụ tiêu cực. Kỹ thuật thường được sử dụng để cải thiện ước tính này lặp đi lặp lại là công thức của Rocchio:
<p align="center">
  <img src="https://latex.codecogs.com/svg.latex?Q'=\alpha%20Q+\beta\left(\frac{1}{N_R'}\sum_{i\in%20D_R'}D_i\right)-\gamma\left(\frac{1}{N_N'}\sum_{i\in%20D_N'}D_i\right),\tag{4}" alt="formula"/>
</p>

trong đó Q và Q′ là truy vấn gốc và truy vấn đã cập nhật, tương ứng,$D_R'$ và $D_N'$ là các mẫu tích cực và tiêu cực được người dùng trả về, NR′ , NN ′ là số lượng mẫu trong $D_R'$ và $D_N'$, tương ứng, và $\alpha, \beta, \gamma$ là các hằng số được chọn. Cả việc điều chỉnh trọng số truy vấn và QPM đều sử dụng lấy mẫu láng giềng gần nhất. Tức là, hệ thống trả về các hình ảnh được xếp hạng hàng đầu để người dùng xem xét và sau đó truy vấn được tinh chỉnh dựa trên phản hồi của người dùng. Các kỹ thuật học máy cũng có thể được sử dụng trong bước 3 của vòng lặp RF. SVM thường được sử dụng để nắm bắt khái niệm truy vấn bằng cách tách các hình ảnh liên quan khỏi các hình ảnh không liên quan bằng cách sử dụng một siêu phẳng trong không gian chiếu. Một ưu điểm của SVM so với các thuật toán học khác nằm ở hiệu suất tổng quát hóa cao mà không cần thêm kiến thức tiên nghiệm. Một ưu điểm khác là nó có thể hoạt động với các tập huấn luyện nhỏ. Để sử dụng hiệu quả các mẫu tiêu cực và không được gán nhãn, và để học một khái niệm truy vấn nhanh hơn và chính xác hơn, một phương pháp học chủ động tên là SVMactive được đề xuất trong tài liệu.
Thông thường, các mẫu được dán nhãn do người dùng cung cấp là có giới hạn, và tập dữ liệu huấn luyện nhỏ như vậy sẽ dẫn đến phân loại yếu các ảnh trong cơ sở dữ liệu (là liên quan/không liên quan). Trong tài liệu, D-EM (Discriminant-EM) được sử dụng để nâng cao hiệu suất của bộ phân loại được học từ dữ liệu huấn luyện được dán nhãn hạn chế. D-EM là một phiên bản cải tiến của EM. EM có nhược điểm là một số lượng lớn các tham số phải được ước tính do tính chiều cao của mô hình tạo sinh được sử dụng để mô hình hóa phân bố dữ liệu. D-EM giảm nhẹ vấn đề này bằng cách thêm một bước D. Bước E ước tính tư cách thành viên cho mỗi mẫu không được dán nhãn để bổ sung tập huấn luyện được dán nhãn. Bước D xác định một ánh xạ sao cho dữ liệu được phân cụm trong không gian đặc trưng đã ánh xạ (một không gian con phân biệt). Dựa trên tập dữ liệu được bổ sung, bước M ước tính các tham số của mô hình tạo sinh trong không gian phân biệt chiều thấp hơn.
Trong một số bài báo, các phương pháp học cây quyết định như C4.5, ID3 được sử dụng trong vòng lặp RF để phân loại các hình ảnh cơ sở dữ liệu thành hai lớp (liên quan/không liên quan) tùy thuộc vào việc chúng có tương tự hình ảnh truy vấn hay không. Sau đó, các hình ảnh liên quan được trình bày cho người dùng để tiếp tục vòng RF khác. Có nhiều phương pháp khác nhau áp dụng các giả định hoặc thiết lập vấn đề khác nhau, mặc dù dưới cùng một khái niệm "RF". Một khảo sát chi tiết hơn có thể được tìm thấy trong tài liệu. Hầu hết các hệ thống dựa trên RF hiện tại chỉ sử dụng các đặc trưng ảnh cấp thấp để ước tính các tham số truy vấn lý tưởng và không giải quyết nội dung "ngữ nghĩa" của ảnh. Hệ thống như vậy hoạt động tốt nếu các vector đặc trưng có thể mô tả truy vấn tốt. Tuy nhiên, đối với đối tượng cụ thể không thể được biểu diễn đầy đủ bằng các đặc trưng cấp thấp, các hệ thống RF này sẽ không trả về nhiều kết quả liên quan ngay cả với một số lượng lớn phản hồi từ người dùng. Để giải quyết các hạn chế của các hệ thống như vậy, tài liệu cung cấp một hệ thống tên là "iFind" thực hiện RF trên cả các vector đặc trưng cấp thấp và nội dung ngữ nghĩa của ảnh được biểu diễn bằng từ khóa. Đầu tiên, một mạng ngữ nghĩa được xây dựng trên một cơ sở dữ liệu ảnh và một kỹ thuật học máy đơn giản được sử dụng để học từ các truy vấn và phản hồi của người dùng để cải thiện thêm mạng ngữ nghĩa này. Với mạng ngữ nghĩa được hình thành trên cơ sở liên kết từ khóa với các ảnh, hệ thống có thể suy ra chính xác nội dung ngữ nghĩa của ảnh cho mục đích truy xuất. Bằng cách này, RF dựa trên ngữ nghĩa và đặc trưng cấp thấp được tích hợp liền mạch. Các thử nghiệm trên các bộ sưu tập ảnh thực tế chứng minh độ chính xác và hiệu quả của nó.
Trong hầu hết các hệ thống dựa trên RF, phép đo độ tương đồng được cố định trong khi tầm quan trọng hoặc trọng số của mỗi mô tả được ước tính thông qua RF từ người dùng. Ngược lại với cách tiếp cận thông thường này, Doulamis’ đã đề xuất một thuật toán RF phi tuyến tổng quát cho truy xuất hình ảnh. Trong cách tiếp cận này, thay vì điều chỉnh mức độ quan trọng của mỗi mô tả, chính phép đo độ tương đồng được ước tính thông qua một cơ chế học trực tuyến. Phương pháp này dựa trên ước tính tối ưu đệ quy của một mối quan hệ tham số phi tuyến của các thành phần chức năng đã biết. Tuy nhiên, do vấn đề tối ưu hóa, tính toán có thể tốn kém và thuật toán có thể bị kẹt vào các cực tiểu cục bộ.